{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet InPoDa :\n",
    "Dans le c√¢dre du TD11-12 nous devions travailler sur un programme permettant de fournir de la statistique sur des tweet r√©cup√©r√©s sous format *json*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "### Import des librairies ###\n",
    "import json, re\n",
    "from textblob import TextBlob\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import matplotlib #pas encore utilis√©\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "###########################Fonctions###########################\n",
    "def Tweet(data:dict):\n",
    "    '''Prend un tweet sous format dictionnaire.\\n \n",
    "    Proc√®de √† un tri des informations pour ne garder que l'essentiel.\\n\n",
    "    Renvoi un nouveau dictionnaire avec des donn√©es pr√™tes √† l'emploi. '''\n",
    "    self = {}\n",
    "    self['text'] = data['text']\n",
    "    self['cleaned_text'] = data['text']\n",
    "    self['author'] = data['author_id']\n",
    "    self['hashtags'] = []\n",
    "    self['urls'] = []\n",
    "    self['mentions'] = []\n",
    "    self['topics'] = []\n",
    "    if 'entities' in data.keys():\n",
    "        if 'hashtags' in data['entities']:\n",
    "            for i in data['entities']['hashtags']:\n",
    "                if i['tag'] not in self['hashtags']:\n",
    "                    self['hashtags'].append(i['tag'])\n",
    "        if 'urls' in data['entities']:\n",
    "            for i in data['entities']['urls']:\n",
    "                if i['url'] not in self['urls']: \n",
    "                    self['urls'].append(i['url'])\n",
    "                    self['cleaned_text'] = self['cleaned_text'].replace(i['url'],'')\n",
    "        if 'mentions' in data['entities']:\n",
    "            for i in data['entities']['mentions']:\n",
    "                if i['id'] not in self['mentions']:\n",
    "                    self['mentions'].append(i['id'])\n",
    "    if 'context_annotations' in data.keys():\n",
    "        for i in data['context_annotations']:\n",
    "            if i['entity']['name'] not in self['topics']:\n",
    "                self['topics'].append(i['entity']['name'])\n",
    "    self['cleaned_text'] = re.sub(r'#\\w+|@\\w+|(\\r\\n|\\r|\\n)|[^a-zA-Z√†√¢√ß√©√®√™√´√Æ√Ø√¥√ª√π√º√¶≈ì\\d\\s]','',self['cleaned_text'])\n",
    "    self['cleaned_text'] = re.sub(r'^ +','',self['cleaned_text'])\n",
    "    self['sentiment'] = TextBlob(self['cleaned_text']).sentiment\n",
    "    return self\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InPoDa():\n",
    "    def __init__(self, json_path):\n",
    "        '''# Utilit√© :\\n\n",
    "        Permet d'initialiser une instance InPoDa selon un json\n",
    "        contenant des tweets, vous pouvez ensuite appeler ses diff√©rentes m√©thodes\n",
    "        pour acc√®der √† diff√©rent stats.'''\n",
    "        with open(json_path) as f:\n",
    "            self.json = json.load(f)\n",
    "        self.TweetData = []\n",
    "        for raw in self.json:\n",
    "            self.TweetData.append(Tweet(raw))\n",
    "        self.pub_per_users = {}\n",
    "        self.pub_per_tag = {}\n",
    "        self.pub_per_topic = {}\n",
    "        for i in self.TweetData:\n",
    "            if i['author'] in self.pub_per_users.keys():\n",
    "                self.pub_per_users[i['author']] += 1\n",
    "            else:\n",
    "                self.pub_per_users[i['author']] = 1\n",
    "            for tag in i['hashtags']:\n",
    "                if tag in self.pub_per_tag.keys():\n",
    "                    self.pub_per_tag[tag] += 1\n",
    "                else:\n",
    "                    self.pub_per_tag[tag] = 1\n",
    "            for topic in i['topics']:\n",
    "                if topic in self.pub_per_topic.keys():\n",
    "                    self.pub_per_topic[topic] += 1\n",
    "                else:\n",
    "                    self.pub_per_topic[topic] = 1\n",
    "\n",
    "    \n",
    "    def top_k_hashtags(self,k):\n",
    "        '''Retourne le top k des Hashtags les plus utilis√©s dans l'instance'''\n",
    "        return sorted(self.pub_per_tag.items(), key=lambda x:x[1],reverse=True)[:k]\n",
    "    \n",
    "    def top_k_user(self,k):\n",
    "        '''Retourne le top k des utilisateurs les plus actifs dans l'instance'''\n",
    "        return sorted(self.pub_per_users.items(), key=lambda x:x[1],reverse=True)[:k]\n",
    "    \n",
    "    def top_k_mentionned_user(self,k):\n",
    "        '''Retourne le top k des utilisateurs les plus mentionn√©s dans l'instance'''\n",
    "        mentions = {}\n",
    "        for tweet in self.TweetData:\n",
    "            for user in tweet['mentions']:\n",
    "                if user in mentions.keys():\n",
    "                    mentions[user] += 1\n",
    "                else:\n",
    "                    mentions[user] = 1\n",
    "        return sorted(mentions.items(), key=lambda x:x[1],reverse=True)[:k]\n",
    "    \n",
    "    def top_k_topic(self,k):\n",
    "        '''Retourne le top k des topics les plus mentionn√©s dans l'instance'''\n",
    "        return sorted(self.pub_per_topic.items(), key=lambda x:x[1],reverse=True)[:k]\n",
    "    \n",
    "    def get_user_tweets(self,user_id:str):\n",
    "        '''Retourne tout les tweets d'un utilisateur existant dans l'instance'''\n",
    "        output = []\n",
    "        for tweet in self.TweetData:\n",
    "            if tweet['author'] == user_id:\n",
    "                output.append(tweet)\n",
    "        return output\n",
    "    \n",
    "    def get_tweets_user_mentionned(self,user_id:str):\n",
    "        '''Retourne tout les tweets o√π utilisateur existant dans l'instance est mentionn√©'''\n",
    "        output = []\n",
    "        for tweet in self.TweetData:\n",
    "            for m_id in tweet['mentions']:\n",
    "                if m_id == user_id:\n",
    "                    output.append(tweet)\n",
    "        return output\n",
    "    \n",
    "    def get_users_by_hashtag(self,tag:str):\n",
    "        '''Retourne tout les utilisateurs de ce Hashtag'''\n",
    "        output = {}\n",
    "        for tweet in self.TweetData:\n",
    "            for hashtag in tweet['hashtags']:\n",
    "                if tag == hashtag:\n",
    "                    if tweet['author'] not in output.keys():\n",
    "                        output[tweet['author']] = 1\n",
    "                    else:\n",
    "                        output[tweet['author']] += 1\n",
    "        return output\n",
    "    \n",
    "    def get_author_mentions(self,user_id:str):\n",
    "        '''Retourne toutes les mentions que cet utilisateur a fait'''\n",
    "        output = {}\n",
    "        for tweet in self.TweetData:\n",
    "            if tweet['author'] == user_id:\n",
    "                for m in tweet['mentions']:\n",
    "                    if m not in output.keys():\n",
    "                        output[m] = 1\n",
    "                    else:\n",
    "                        output[m] += 1\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D√©monstration √† l'usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance1 = InPoDa('versailles_tweets_100.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1339914264522461187', 4), ('992904738516717570', 4), ('717025418', 2), ('3169236915', 2), ('372993152', 2)]\n"
     ]
    }
   ],
   "source": [
    "print(instance1.top_k_user(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CIV', 2), ('twitter225', 1), ('SupportriceMazo', 1), ('domie', 1), ('jifa', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(instance1.top_k_hashtags(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3200704501', 3), ('19811019', 2), ('4827016745', 1), ('254068589', 1), ('781489936184651776', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(instance1.top_k_mentionned_user(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Tokyo 2020 Summer Olympics', 2), ('Annie Mac', 2), ('Max Gradel', 1), ('Eric Bailly', 1), ('Jungle Cruise', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(instance1.top_k_topic(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1339914264522461187': 4, '717025418': 2, '992904738516717570': 4, '736523371': 1, '1471684208': 1, '3169236915': 2, '16267684': 1, '60117154': 1, '372993152': 2, '105241852': 1, '2357913366': 1}\n"
     ]
    }
   ],
   "source": [
    "print(instance1.pub_per_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'twitter225': 1, 'SupportriceMazo': 1, 'domie': 1, 'CIV': 2, 'jifa': 1, 'versailles': 1, 'nocturne': 1, 'appollon': 1}\n"
     ]
    }
   ],
   "source": [
    "print(instance1.pub_per_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tokyo 2020 Summer Olympics': 2, 'Max Gradel': 1, 'Eric Bailly': 1, 'Jungle Cruise': 1, 'Action & adventure films': 1, 'Annie Mac': 2, 'Yebba': 1, 'Jazz': 1}\n"
     ]
    }
   ],
   "source": [
    "print(instance1.pub_per_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': '@isabelle170516 @leonna_julie @Steiner2502 Vous avez tt √† fait raison! le silence incompr√©hensible du gouver-noument et des merdias sur ce tr√®s important et dramatique sujet prouve de mani√®re irr√©futable\\n leur implication √† ce plan  diabolique maquill√©!', 'cleaned_text': 'Vous avez tt √† fait raison le silence incompr√©hensible du gouvernoument et des merdias sur ce tr√®s important et dramatique sujet prouve de mani√®re irr√©futable leur implication √† ce plan  diabolique maquill√©', 'author': '992904738516717570', 'hashtags': [], 'urls': [], 'mentions': ['781489936184651776', '3200704501', '1246352652700659713'], 'topics': [], 'sentiment': Sentiment(polarity=0.4, subjectivity=1.0)}, {'text': '@LynLyna12 @leonna_julie La grande muette continue et continuera de le rester! √Ä part quelques irr√©ductibles √† la retraite?', 'cleaned_text': 'La grande muette continue et continuera de le rester  part quelques irr√©ductibles √† la retraite', 'author': '992904738516717570', 'hashtags': [], 'urls': [], 'mentions': ['1355767640036438016', '3200704501'], 'topics': [], 'sentiment': Sentiment(polarity=0.0, subjectivity=0.0)}, {'text': \"@leonna_julie Le rdv aujourd'hui aura  tenu ses promesses!üëçü§ó‚úåÔ∏è‚úäüèº‚úäüèº\\n Pour les probl√®mes de sommeil  1 cachet √† la m√©latonine 1,80 mg et je dors comme un b√©b√©!  R√©veil en pleine forme assur√©!üí™üèº Et sans acoutumances, pas comme avec ces b√©quilles chimiques!üòµ\\u200düí´\\nBonne soir√©e Julie!üåÜüåà https://t.co/F6zvVfWwAf\", 'cleaned_text': 'Le rdv aujourdhui aura  tenu ses promesses Pour les probl√®mes de sommeil  1 cachet √† la m√©latonine 180 mg et je dors comme un b√©b√©  R√©veil en pleine forme assur√© Et sans acoutumances pas comme avec ces b√©quilles chimiquesBonne soir√©e Julie ', 'author': '992904738516717570', 'hashtags': [], 'urls': ['https://t.co/F6zvVfWwAf'], 'mentions': ['3200704501'], 'topics': [], 'sentiment': Sentiment(polarity=0.0, subjectivity=0.0)}, {'text': \"@Polo82810715 @lrestistant73 Un mouton c'est  bien plus intelligent que toi! ü™≥\", 'cleaned_text': 'Un mouton cest  bien plus intelligent que toi ', 'author': '992904738516717570', 'hashtags': [], 'urls': [], 'mentions': ['1071056487278104577', '4216955975'], 'topics': [], 'sentiment': Sentiment(polarity=0.8, subjectivity=0.9)}]\n"
     ]
    }
   ],
   "source": [
    "print(instance1.get_user_tweets('992904738516717570'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': '@isabelle170516 @leonna_julie @Steiner2502 Vous avez tt √† fait raison! le silence incompr√©hensible du gouver-noument et des merdias sur ce tr√®s important et dramatique sujet prouve de mani√®re irr√©futable\\n leur implication √† ce plan  diabolique maquill√©!', 'cleaned_text': 'Vous avez tt √† fait raison le silence incompr√©hensible du gouvernoument et des merdias sur ce tr√®s important et dramatique sujet prouve de mani√®re irr√©futable leur implication √† ce plan  diabolique maquill√©', 'author': '992904738516717570', 'hashtags': [], 'urls': [], 'mentions': ['781489936184651776', '3200704501', '1246352652700659713'], 'topics': [], 'sentiment': Sentiment(polarity=0.4, subjectivity=1.0)}, {'text': '@LynLyna12 @leonna_julie La grande muette continue et continuera de le rester! √Ä part quelques irr√©ductibles √† la retraite?', 'cleaned_text': 'La grande muette continue et continuera de le rester  part quelques irr√©ductibles √† la retraite', 'author': '992904738516717570', 'hashtags': [], 'urls': [], 'mentions': ['1355767640036438016', '3200704501'], 'topics': [], 'sentiment': Sentiment(polarity=0.0, subjectivity=0.0)}, {'text': \"@leonna_julie Le rdv aujourd'hui aura  tenu ses promesses!üëçü§ó‚úåÔ∏è‚úäüèº‚úäüèº\\n Pour les probl√®mes de sommeil  1 cachet √† la m√©latonine 1,80 mg et je dors comme un b√©b√©!  R√©veil en pleine forme assur√©!üí™üèº Et sans acoutumances, pas comme avec ces b√©quilles chimiques!üòµ\\u200düí´\\nBonne soir√©e Julie!üåÜüåà https://t.co/F6zvVfWwAf\", 'cleaned_text': 'Le rdv aujourdhui aura  tenu ses promesses Pour les probl√®mes de sommeil  1 cachet √† la m√©latonine 180 mg et je dors comme un b√©b√©  R√©veil en pleine forme assur√© Et sans acoutumances pas comme avec ces b√©quilles chimiquesBonne soir√©e Julie ', 'author': '992904738516717570', 'hashtags': [], 'urls': ['https://t.co/F6zvVfWwAf'], 'mentions': ['3200704501'], 'topics': [], 'sentiment': Sentiment(polarity=0.0, subjectivity=0.0)}]\n"
     ]
    }
   ],
   "source": [
    "print(instance1.get_tweets_user_mentionned('3200704501'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1339914264522461187': 2}\n"
     ]
    }
   ],
   "source": [
    "print(instance1.get_users_by_hashtag('CIV'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'781489936184651776': 1, '3200704501': 3, '1246352652700659713': 1, '1355767640036438016': 1, '1071056487278104577': 1, '4216955975': 1}\n"
     ]
    }
   ],
   "source": [
    "print(instance1.get_author_mentions('992904738516717570'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface Utilisateur du Programme :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process():\n",
    "    global instance1\n",
    "    instance1 = InPoDa(var_path.get())\n",
    "    var_infoproc.set(str(len(instance1.TweetData))+' tweets trouv√©s.')\n",
    "    label_infoproc.grid(column=0,row=4)\n",
    "\n",
    "def browse():\n",
    "    var_path.set(filedialog.askopenfilename(title='Select your JSON'))\n",
    "\n",
    "def view_tweet():\n",
    "    instance1.TweetData\n",
    "\n",
    "def user_request(m:str):\n",
    "    if m == 'tku':\n",
    "        instance1.top_k_user(int(var_entry.get()))\n",
    "    elif m == 'tkmu':\n",
    "        instance1.top_k_mentionned_user(int(var_entry.get()))\n",
    "    elif m == 'tkh':\n",
    "        instance1.top_k_hashtags(int(var_entry.get()))\n",
    "    elif m == 'tkt':\n",
    "        instance1.top_k_topic(int(var_entry.get()))\n",
    "    elif m == 'gumt':\n",
    "        instance1.get_tweets_user_mentionned(var_entry.get())\n",
    "    elif m == 'guh':\n",
    "        instance1.get_users_by_hashtag(var_entry.get())\n",
    "    elif m == 'gam':\n",
    "        instance1.get_author_mentions(var_entry.get())\n",
    "    elif m == 'gut':\n",
    "        instance1.get_user_tweets(var_entry.get())\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"InPoDa\")\n",
    "\n",
    "var_entry = tk.StringVar()\n",
    "var_path = tk.StringVar(value='There is no path selected')\n",
    "var_infoproc = tk.StringVar()\n",
    "\n",
    "button_browse = tk.Button(root, text='Browse for JSON', command=browse)\n",
    "label_path = tk.Label(root, textvariable=var_path)\n",
    "entry = tk.Entry(root, textvariable = var_entry)\n",
    "button_proc = tk.Button(root, text='Process', command=process)\n",
    "label_infoproc = tk.Label(root,textvariable=var_infoproc)\n",
    "button_view_tweet = tk.Button(root, text='View tweets', command=view_tweet)\n",
    "\n",
    "button_topkUsers = tk.Button(root, text='Browse for JSON', command=lambda:user_request('tku'))\n",
    "button_topkMentionnedUsers = tk.Button(root, text='Browse for JSON', command=lambda:user_request('tkmu'))\n",
    "button_topkHashtags = tk.Button(root, text='Browse for JSON', command=lambda:user_request('tkh'))\n",
    "button_topkTopics = tk.Button(root, text='Browse for JSON', command=lambda:user_request('tkt'))\n",
    "button_getUserMentionnedTweet = tk.Button(root, text='Browse for JSON', command=lambda:user_request('gumt'))\n",
    "button_getUsersHashtags = tk.Button(root, text='Browse for JSON', command=lambda:user_request('guh'))\n",
    "button_getAuthorMentions = tk.Button(root, text='Browse for JSON', command=lambda:user_request('gam'))\n",
    "button_getUserTweets = tk.Button(root, text='Browse for JSON', command=lambda:user_request('gut'))\n",
    "\n",
    "\n",
    "button_browse.grid(column=0,row=0)\n",
    "label_path.grid(column=0,row=1)\n",
    "entry.grid(column=0,row=2)\n",
    "button_proc.grid(column=0,row=3)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
