{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import re, random\n",
    "\n",
    "class InPoDa:\n",
    "    def __init__(self, json_path):\n",
    "        df_tweets = pd.read_json(json_path)\n",
    "        del df_tweets['_id'], df_tweets['public_metrics'], df_tweets['conversation_id'], df_tweets['geo'], df_tweets['lang'], df_tweets['created_at'], df_tweets['attachments']\n",
    "        hashtags = []\n",
    "        mentions = []\n",
    "        urls = []\n",
    "        for i in df_tweets['entities']:\n",
    "            try:\n",
    "                hashtags.append(list(dict.fromkeys([j['tag'] for j in i['hashtags']])))\n",
    "            except:\n",
    "                hashtags.append([])\n",
    "\n",
    "            try:\n",
    "                mentions.append([j['id'] for j in i['mentions']])\n",
    "            except:\n",
    "                mentions.append([])\n",
    "    \n",
    "            try:\n",
    "                urls.append([j['url'] for j in i['urls']])\n",
    "            except:\n",
    "                urls.append([])\n",
    "\n",
    "        cleaned_text = []\n",
    "        for r,i in enumerate(df_tweets['text']):\n",
    "            for j in urls[r]:\n",
    "                i = i.replace(j,'')\n",
    "            cleaned_text.append(re.sub(r'#\\w+|@\\w+|(\\r\\n|\\r|\\n)|[^a-zA-Zàâçéèêëîïôûùüæœ\\d\\s]','',i))\n",
    "\n",
    "        topics = []\n",
    "        for r,i in enumerate(df_tweets['context_annotations']):\n",
    "            try:\n",
    "                topics.append(list(dict.fromkeys([j['entity']['name'] for j in i])))\n",
    "            except:\n",
    "                try:\n",
    "                    words = sorted(cleaned_text[r].split(),key=len,reverse=True)\n",
    "                    topics.append([random.choice(words[:len(words)//3])])\n",
    "                except:\n",
    "                    topics.append([])\n",
    "\n",
    "        sentiments = []\n",
    "        for i in cleaned_text:\n",
    "            sentiments.append(TextBlob(i).sentiment)\n",
    "\n",
    "        df_tweets['hashtags'] = hashtags\n",
    "        df_tweets['mentions'] = mentions\n",
    "        df_tweets['urls'] = urls\n",
    "        df_tweets['topics'] = topics\n",
    "        df_tweets['cleaned_text'] = cleaned_text\n",
    "        df_tweets['sentiments'] = sentiments\n",
    "        del df_tweets['context_annotations'], df_tweets['entities']\n",
    "        self.dataframe = df_tweets\n",
    "        self.data = df_tweets.to_dict('records')\n",
    "        \n",
    "        # Fenêtre de dialogue #\n",
    "        print(50*'*'+\"\\nInstance InPoDa initialisée avec succès\\n\"+50*'*'+'\\n%d tweets détectés dans \"'%len(self.data)+json_path+'\"')\n",
    "    \n",
    "    def _show(self, xy):\n",
    "        x, y = xy\n",
    "        freq_series = pd.Series(y)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        fig = freq_series.plot(kind='bar')\n",
    "        fig.set_title('Amount Frequency')\n",
    "        fig.set_xlabel('Elements')\n",
    "        fig.set_ylabel('Frequency')\n",
    "        fig.set_xticklabels(x)\n",
    "    \n",
    "    def top_k_users(self,k:int):\n",
    "        top = self.dataframe['author_id'].value_counts().iloc[0:k]\n",
    "        self._show([list(top.index), list(top.values)])\n",
    "    \n",
    "    def _count_df_occ(self,arg:str,explore_list:bool):\n",
    "        occ = {}\n",
    "        for i in self.dataframe[arg]:\n",
    "            if explore_list:\n",
    "                for j in i:\n",
    "                    if j in occ.keys():\n",
    "                        occ[j] += 1\n",
    "                    else:\n",
    "                        occ[j] = 1\n",
    "            else:\n",
    "                if i in occ.keys():\n",
    "                    occ[i] += 1\n",
    "                else:\n",
    "                    occ[i] = 1\n",
    "        return occ\n",
    "    \n",
    "    def _top_k(self,arg:str,k:int,explore_list=True):\n",
    "        l1, l2 = [], []\n",
    "        dictionnaire = self._count_df_occ(arg, explore_list)\n",
    "        for key in sorted(dictionnaire, key=dictionnaire.get, reverse=True):\n",
    "            l1.append(key)\n",
    "            l2.append(dictionnaire[key])\n",
    "        return [l1[:k],l2[:k]]\n",
    "\n",
    "    def top_k_hashtags(self,k:int):\n",
    "        self._show(self._top_k('hashtags',k))\n",
    "    \n",
    "    def top_k_mentions(self, k:int):\n",
    "        self._show(self._top_k('mentions',k))\n",
    "    \n",
    "    def top_k_topics(self, k:int):\n",
    "        self._show(self._top_k('topics',k))\n",
    "    \n",
    "    def nb_pubs_per_user(self):\n",
    "        self._show(self._top_k('author_id',len(self.data), False))\n",
    "    \n",
    "    def nb_pubs_per_hashtag(self):\n",
    "        self._show(self._top_k('hashtags',len(self.data)))\n",
    "    \n",
    "    def nb_pubs_per_topic(self):\n",
    "        self._show(self._top_k('topics',len(self.data)))\n",
    "    \n",
    "    def tweets_of(self,user:int):\n",
    "        output = []\n",
    "        for tweet in self.data:\n",
    "            if tweet['author_id'] == user:\n",
    "                output.append(tweet)\n",
    "        return output\n",
    "    \n",
    "    def tweets_that_mention(self,user:int):\n",
    "        output = []\n",
    "        user = str(user)\n",
    "        for tweet in self.data:\n",
    "            for m in tweet['mentions']:\n",
    "                if m == user:\n",
    "                    output.append(tweet)\n",
    "        return output\n",
    "\n",
    "    def users_that_mention_hashtag(self,tag:str):\n",
    "        output = []\n",
    "        for tweet in self.data:\n",
    "            for t in tweet['hashtags']:\n",
    "                if t == tag:\n",
    "                    output.append(tweet['author_id'])\n",
    "        return list(dict.fromkeys(output))\n",
    "    \n",
    "    def users_mentionned_by(self,user:int):\n",
    "        output = []\n",
    "        for tweet in self.data:\n",
    "            if tweet['author_id'] == user:\n",
    "                output = output + tweet['mentions']\n",
    "        return list(dict.fromkeys(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Instance InPoDa initialisée avec succès\n",
      "**************************************************\n",
      "20 tweets détectés dans \"versailles_tweets_100.json\"\n"
     ]
    }
   ],
   "source": [
    "path = \"versailles_tweets_100.json\"\n",
    "instance1 = InPoDa(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instance1.top_k_users(3)\n",
    "#instance1.top_k_hashtags(4)\n",
    "#instance1.top_k_mentions(4)\n",
    "#instance1.top_k_topics(3)\n",
    "#instance1.nb_pubs_per_user()\n",
    "#instance1.nb_pubs_per_hashtag()\n",
    "#instance1.nb_pubs_per_topic()\n",
    "#instance1.tweets_of(717025418)\n",
    "#instance1.tweets_that_mention(19811019)\n",
    "#instance1.users_that_mention_hashtag('CIV')\n",
    "#instance1.users_mentionned_by(992904738516717568)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
